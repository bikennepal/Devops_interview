Let's prepare for the devops interview now

===============================
Linux Interview questions
Where does dns cache located in linux?
ans: /var/cache/nsdc/hosts

**swap memory in linux, projects worked on , explain CI/CD , docker, kubernetes
* What is a swap memory and how can you create swap memory and see swap memory?
Ans: Swap space in Linux is an extension of physical RAM, offering virtual memory that helps maintain system stability and performance
swapon -s to see swap space 
free -m this gives more detail

How to Increase/Decrease Swap Space
swapon --show 
Before resizing, disable the swap space with the following syntax:
	sudo swapoff -v /[swap_path]
After resizing the swap partition, update the partition table using the following syntax:
sudo mkswap /[swap_path]
sudo swapon /[swap_path]
How to see the cpu info on linux?


see here for sre questions:
https://www.ambitionbox.com/interviews/signzy-technologies-interview-questions/site-reliability-engineer

What is the difference between SLA,SLI and SLO?
=> sla:An agreement between a company and its customers that defines measurable metrics like uptime, responsiveness, and responsibilities. SLAs are used externally to define the company's service. If the SLA is not met, the company may face a penalty, such as a partial refund or additional subscription time.
slo:An agreement within an SLA that defines a specific metric, such as uptime or response time. SLOs are individual promises made to customers and are measured internally to determine if the SLA is being met

SLI:A specific metric that measures some aspect of the level of service to customers. SLIs are a sub-section of SLOs and are key metrics used to determine if the SLO is being met. The value of the SLI must always meet or exceed the value determined by the SLO.

1. your Ec2 instance is runnning out of disk space what action you will take?
Ans: check the logs and rotate using roatare command in linux check the cpu utulization and memeory as well.
zip the logs using tar -czvf message.tar.zip files.

2. what is a bastion host or a gateway? and what role does it play?
ans:bastion server is a server which act as a door to the internal network and it provide an extra layer of security as well through which can manage all the user at one place

3.multiple ec2 instance are getting terminated in ASG and this is causing issue in application downtime. but there is no issue in ec2 pricing and all quota looks good.
Ans:there can be disk space issue,memory,process and there can not any issue with ASG and amazon service.

4.create a linux script that will automitically push certain logs to s3 bucket and also script should run at particular time.
ans:

5.Why is logging important? what is centralized logging and what tool helps us to achive the same.
ans: we can have logs in elastic search, s3 bucket, cloudwatch etc.
6. how can we list all the users in a group in linux.
Ans:we can use group groupname. or getent group groupname
7.To create a group in linux
Ans: sudo groupadd biken
8.To add user in a group
Ans: sudo usermod -aG group username


7.what is AWK command in linux? and how to use it?
ans: this is a powerrful textprocessing command in linux.
	example:
			$cat > employee.txt 
						ajay manager account 45000
						sunil clerk account 25000
						varun manager sales 50000
						amit manager account 47000
						tarun peon sales 15000
						deepak clerk sales 23000
						sunil peon sales 13000
						satvik director purchase 80000 
awk '/manager/ {print}' employee.txt 
url to know more: https://www.geeksforgeeks.org/awk-command-unixlinux-examples/



8.how to connect to ec2 instance if we lost the key?
Ans: Try this out and understand the real use case.
9.What are the types of EBS we have?
Ans: general purpose gp3,gp2,Iops and magnetic types ebs we have.
10. Can we use one ebs volume by multiple instance?
ans: can shared instances in the same AZ
10. What is the max iops we can get in aws ebs?
Ans: For standard volumes, the maximum size is 16 TiB. For Provisioned IOPS (IO1) and General Purpose (GP2) volumes, the maximum size is 64 TiB.
11.What is the difference between values and snapshots?
Ans: Value is the data of ec2 instance and snapshot is the the backup of the value. and it is layerby layer backup.

12. Can we attach snapshots with ec2 instance? if yes how and if no why?
Ans: You can't use snapshots to launch a new instance, but you can use them to replace volumes on an existing instance.
13.What is the difference between ebs efs and s3 storage?
Ans: https://www.google.com/search?q=What+is+the+difference+between+ebs+efs+and+s3+storage&rlz=1C1GCEA_enIN902IN902&oq=What+is+the+difference+between+ebs+efs+and+s3+storage&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBBzkxOGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8
** Can we launch an instance using efs in aws?
Ans: Yes, you can use Amazon Elastic File System (EFS) to launch an Amazon EC2 instance by creating an EFS file system and mounting it to the instance during launch using the Amazon EFS Quick Create feature. EFS is a serverless, shared file system that can be mounted to multiple EC2 instances and is designed to be a durable and highly available file storage solution
14.Give me some example where vertical scaling is apporopriate then horizantal scaling.
Ans: When you have a small, predictable workload, When you need to quickly improve performance:
15.Name three aws services where we can run kubernetes.
Ans: EKS,ECS and EKS anywere.
16.What are cloud computing deployment models?
Ans: Cloud computing deployment models are the different ways that cloud computing resources can be delivered to and used by customers. There are four main deployment models:
	public,private,cumminity,hybrid
17.What is a shared responsible model?
Ans:In cloud computing, a shared responsibility model is a security framework that outlines the security responsibilities of both the cloud provider and the cloud customer. The model is based on the principle that both parties have shared responsibility for securing the cloud environment.

18.

=====================================
Git need to write all the commands

1. how do you pass message when you make a git commit
ans: we can use git commit -m "updated file"

2.how to change new machine type and check who made last change to that particular git code. and know about blame in git.
ans: git blame biken.txt

3.What is a branch protection in github?
ans:protecting a branch from direct commit by reviewing the change made to other branch and this is not enabled by default in github.

==========================================
Docker:
1.how to check logs in docker and filter only last 200 lines
Ans:docker logs --tail 200 container-name/id
2.will the docker logs be lost if contianer is restarted or stopped.
Ans: Logs will be lost if container is stopped or restarted but we won't find logs if it got deleted.
To persist Docker logs, you can use a logging driver such as json-file or syslog. These drivers will store the logs in a location on the host machine, which will persist even after the container is stopped or restarted.
You can also use a third-party logging service such as Splunk or Elasticsearch to store Docker logs. These services will collect and store the logs from all of your containers, and provide you with a centralized view of your logs.
3.You encounter a docker image of size 2.7gb will this be a cause of concern and how you will tackle this?
Ans:Bigger images will result in longer built time
    docker image download or API limit error
    application will also be bulkier or heavy
       
Solution:
    smaller image base like alpine images
    Multi-stage Builds Feature when building docker image
    install only required packages or bianries
4.What is the difference between docker image and docker layer?
Ans:docker image a packaged application or a bundle of packaged layers where it contains all the code and dependencies to run an application.

5.Explain CMD and entrypoint in Docker and are these two same?
ans:CMD Sets default parameters that can be overridden from the Docker command line interface (CLI) while running a docker container while 
Sets default parameters that cannot be overridden while executing Docker containers with CLI parameters.

FROM nginx:latest

ENTRYPOINT ["echo", "Biken"]

The above entrypoint cannot be overriden and if we try to override it won't work

docker build -t hell-biken
docker run hello-biken biken
Biken biken




FROM ubuntu
ENTRYPOINT ["echo", "Hello"]
CMD ["Abhinav"]
if we don't give any name in cmd it will print hello only
FROM ubuntu
ENTRYPOINT ["echo", "Hello World"]

FROM ubuntu
CMD ["echo", "Hello World"]


What are the different components of Docker?
Docker clinet, docker-daemon, docker-registry,docker-image,docker-swarm.

What are Docker volumes?
a volume is a persistent storage location that exists outside of the container. Volumes are useful for storing data that needs to persist even if the container is stopped or removed.

VOLUME /var/log 
VOLUME /my/data 

or we can specify volume while running a docker container
docker run -v /host/log:/var/log myimage  this will be managed by docker-engine itself and this type is of Volume.

docker volume create my-volume
docker volume create --name shared-data
we must mount the created volume inside the container
docker run -it --name my-container -v my-volume:/data ubuntu:latest

* can we use same volume with multiple containers
Ans: There are two ways to share a single volume with multiple Docker containers:
	Using the volumes-from flag: This flag allows you to mount the volumes of one container to another container. For example, to mount the volumes of the container named container1 to the container named container2, you would run the following command:
	docker run -it --name container2 -v my-volume:/data ubuntu


What is the difference between docker and virtual machine?
Ans: Docker is a light weight mean to host application and VM is a whole Os which is heavy and requires more cpu,Ram to function properly
How can you enable a container to start a docker container when host machine is restarted?
Ans: yeah we can enable to start container when host restared by updating restart policy.
		docker update --restar=always container_id
	To create a systemd unit file for a docker container, you would create a file with the .service extension in the /etc/systemd/system directory. The file would contain the following information:
	[Unit]
Description=My Docker Container
After=network.target

[Service]
Type=simple
ExecStart=/usr/bin/docker start my-container
ExecStop=/usr/bin/docker stop my-container

[Install]
WantedBy=multi-user.target

sudo systemctl enable my-container.service
sudo systemctl start my-container.service

What is docker compose?
Ans: Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application's services.
 example: 
	

 What are different types of Docker network how they are different form one other?
docker run --network my-network my-image // This is how we can run contaienr in different network
 Ans: Bridge network, overlay and vlan network:
	Overlay: Overlay is a network wherein it enables communcation between the containers hosted in different hosts.
	Bridge: Beidge is a netwrok which enables communication amongs the containers in same host.
	vlan: Macvlan networks allow containers to connect directly to the physical host network. This makes them ideal for applications that need to be able to access the physical host network.
	

 What is a docker image vs docker container?
 Ans: Docker image basically is a package of code where it is mean to run a container later.

 What do you understand by docker volume and why they are used for data persistent?
 Ans: dokcer volume are used to persist data when container are restarted or stopped

 HOw do you torubleshoot container no starting?
 Ans: Docker logs will be the first point, docker inspect,docker events, 
	docker logs container_id or container_name, docker inspect --type=container my_container 

 how to secure docker contianers?
 Ans: The best wasy to protect containers are we should never run docker as root user and scan the images and use ssl singed dockr images.

 Docker multi stage built creation explanation.
 Ans: 

 HOw do you deploy canary deployment using docker?
 Ans:

 What command can you run to export a docker image as an archive?
 Ans: docker export red_panda > latest.tar
	docker export --output="latest.tar" red_panda
	docker export red_panda > latest.tar

 how to mount volume in docker?
 Ans: we can mount volumes in docker at the runtime 
 Basically, there are 3 types of mounts which you can use in your Docker container viz. Volumes, Bind mount and tmpfs mounts.

	Volumes:
	bind Mount:
	Tmpfs: 

How do you exec a command inside a container?
 Ans: docker exec container_id ls

 How can you create a docker image from a running container?
 Ans: yes we can create image from a running container.
	now let's modify the previous docker conatiner running and update a new indx.html file.
index.html is the file that in the current path.

docker cp index.html image_name:/usr/share/nginx/index.html

docker commit image_name    or we can also give here itself  "docker commit image_name new_image_name 

docker tag image_id new_image_name


## Make your own docker app of django and deploy using docker.
Know how Django app works and it's struture.

===================================================

Multistage docker build.

multistage & Distroless
Try to creata simple App 


==========================================
Docker Volumes and Bind mount:
Know the bind and volume difference and try to know docker command to create volume.

===========================================
Docker Network:

difference between bridge overlay and host network in docker.


===============================================


Let's prepare for the devops interview now

===============================
Linux Interview questions

1. your Ec2 instance is runnning out of disk space what action you will take?
Ans: check the logs and rotate using roatare command in linux check the cpu utulization and memeory as well.
zip the logs using tar -czvf message.tar.zip files.

2. what is a bastion host or a gateway? and what role does it play?
ans:bastion server is a server which act as a door to the internal network and it provide an extra layer of security as well through which can manage all the user at one place

3.multiple ec2 instance are getting terminated in ASG and this is causing issue in application downtime. but there is no issue in ec2 pricing and all quota looks good.
Ans:there can be disk space issue,memory,process and there can not any issue with ASG and amazon service.

4.create a linux script that will automitically push certain logs to s3 bucket and also script should run at particular time.
ans:

5.Why is logging important? what is centralized logging and what tool helps us to achive the same.
ans: we can have logs in elastic search, s3 bucket, cloudwatch etc.
6.What is the difference between sepcial permission and access control list(ACL)?
Ans: special permission is like SUID,GUID and Sticky bit:
soS, 4,2,1 t or T for sticky bit.
ACL is more like a redefine or fine-granied level of permission access for a file or a directory and this is applicabel at user or group level and to make this applicable we need to have ACL enable at partition level.
like getfacl and setfacl.
7.what is the difference between s and S in special permission?
ans: s(lowercase) when s appears in the execute permission field. it indicates that the set user ID(suid) or set group(SGID) permission is set. The SUID permission allows a user to execute a file with the permissions of the files owner.likewise the SGID permission allows a user to exeucte a file witht he permisison of the files' group.

example: rwsr-xr-x indicates that the SUID bit is set for the owner.

S(uppercase): when 'S' appears in the execute permission filed. it indicates that the corresponding execute permission is not set and the SUID or SGID permission is not active.
example rw-rw-r would be rwSr-Sr-- if the SUID bit is set for the owner but execute permission is not set.
8.What is the difference between t and T?
Ans: When t appears in the excute permission field for others on a directory. it indicates that the sticky bit is set. The sticky bit on directory is a permission that restricts the deletion of files within the directory to only the file's owner, the directorys owner or the root user.
example: drwxr-xr indicates that the sticky bit is set for others.
same as capital S set but not given execute permission.
9.what is suid ?can you give me an example? how to set suid?
ans:Change user UID on execution. if SETUID bit is set when the file will be executed by a normal user, the process will have same rights as the owner of the file being executed. BAsically the owner of the command will be root user but still normal user can execute it.
example: ls -l/bin/ping 
		chmod u-s /bin/ping 
		chmod 4766 /bin/ping 

10.what is sgid ?can you give me an example? how to set sgid?
ans: SGID -- Set the group ID used on executable files to allow the file to be run as if logged into group (like suid but used file grp permission)
ans: mkdir /amazon
	chgrp biken amazon
	ls -ld amazon
	chmod 2766 amazon
	cd /amazon
	touch vpc
	ls -l 

	example: chgrp lambda amazon // changing the group of the dir amazon
			chmod 2766 amazon // setting the sgid for the dir amazon
			and if you create any file under amazon it will take group as lambda.
11. what is stickybit ?can you give me an example? how to set stickybit?
Ans: Sticky bit is a special file or directory permission and only the owner or root user can delete that file or directory.
	Example: mkdir compute
				chmod 1766 compute
				touch ec2.txt
				ls -ld compute
				su - splunk 
				cd compute
				rem ec2.txt

12.How to enable ACL on a partition?
Ans: mount -o acl /dev/sdb1 /youtube
		getfacl to check the acl is applied in a directory or not

13.how to apply and Acl on a file or a directory?
Ans: setfacl option argument file or dir
		setfacl -m u:manish:rx /dir







=====================================
Git need to write all the commands

1. how do you pass message when you make a git commit
ans: we can use git commit -m "updated file"

2.how to change new machine type and check who made last change to that particular git code. and know about blame in git.
ans: git blame biken.txt

3.What is a branch protection in github?
ans:protecting a branch from direct commit by reviewing the change made to other branch and this is no enabled by default in github.
4. What is a branch in git?
Ans: A branch is a new or a seprate repositort under the main branch which seprates main code with latest code thas has been push to the subbranch.
5.What is tag in git and why it is used?
Ans:TBD with example
6.


==========================================
Docker:
1.how to check logs in docker and filter only last 200 lines
Ans:docker logs --tail 200 container-name/id
2.will the docker logs be lost if contianer is restarted or stopped.
Ans: Logs will be available if container is stopped or restarted but we won't find logs if it got deleted
3.you encounter a docker iamge of size 2.7gb will this be a cause of concern and how you will tackle this?
Ans:Bigger images will result in longer built time
    docker image download or API limit error
    application will also be bulkier or heavy
       
Solution:
    smaller image base like alpine images
    Multi-stage Builds Feature when building docker image
    install only required packages or bianries
4.What is the difference between docker image and docker layer?
Ans:docker image a packaged application or a bundle of packaged layers where it contains all the code and dependencies to run an application.

5.Explain CMD and entrypoint in Docker and are these two same?
ans:CMD Sets default parameters that can be overridden from the Docker command line interface (CLI) while running a docker container while 
Sets default parameters that cannot be overridden while executing Docker containers with CLI parameters.

FROM nginx:latest

ENTRYPOINT ["nginx"]


FROM ubuntu
ENTRYPOINT ["echo", "Hello"]
CMD ["Abhinav"]
	here while running the docker conatiner we can override the cmd argument
		docker run -it image biken
FROM ubuntu
ENTRYPOINT ["echo", "Hello World"]

FROM ubuntu
CMD ["echo", "Hello World"]


What are the different components of Docker?
Docker clinet, docker-daemon, docker-registry,docker-image,docker-swarm.

What are Docker volumes?
a volume is a persistent storage location that exists outside of the container. Volumes are useful for storing data that needs to persist even if the container is stopped or removed.

VOLUME /var/log 
VOLUME /my/data 

or we can specify volume while running a docker container
docker run -v /host/log:/var/log myimage 



======================================================
* Can you please explain kubernetes architecture?
Ans: Kubernetes, or K8s, is an open-source container orchestration platform that uses a master-worker model to manage containerized applications. The master node, also known as the control plane, manages the worker nodes, which can be physical servers or virtual machines. Containers are deployed and executed in the worker nodes, which are encapsulated in pods
	Monitors the cluster
The kube-controller-manager uses the API server to watch the cluster's shared state and makes changes to move the current state closer to the desired state.
Runs controllers
The kube-controller-manager contains multiple controllers that work together to maintain the desired state of the cluster. These controllers include:
Node Controller: Notifies and responds when nodes go down. It also verifies the node's health and checks with the cloud provider's API if the node has been deactivated, deleted, or terminated. If the node has been deleted, the controller deletes the Node object from the cluster.
Replication Controller: Maintains the correct number of pods for each replication controller object.
Endpoints Controller: Populates the Endpoints object, which joins services and pods.
Other responsibilities
The kube-controller-manager is also responsible for creating new Pods, ServiceAccounts, and EndPoints.
Kube-apiserver:Kube-apiserver is responsible for authenticating , validating requests, retrieving and Updating data in ETCD key-value store. In fact kube-apiserver is the only component that interacts directly to the etcd datastore.

Kubelet
An agent that runs on each worker node to manage and maintain pods. The kubelet communicates with the API server to receive pod definitions, monitors pod health, and starts and stops containers as needed.
Kube-proxy
A network proxy that runs on each node to control traffic routing and network connectivity for cluster services.

Kube-scheduler
Records resource utilization statistics for each computing node, evaluates the cluster's health, and decides where and whether to deploy new containers.


ETCD: 
Kubernetes

1.what is kubernetes KOps?
Ans: Kops is an automation tool through which we can automate and bootstrap kubernetes cluseter
2.Explain Replication controller in K8s.
Ans: it is one of the component in kubernetes.
3.What is pv and pvc in kuberntes.
Ans: done   
4.a pod can't access a volume what could be the issue.
Ans: there can be access mode issue or pv type being accessed and ebs can be accessed by one pod and NFS can be by many pods
5.what is a side car container?
Ans:Sidecars are not part of the main traffic or API of the primary application. They usually operate asynchronously and are not involved in the public API. This way, they can enhance the main container without modifying its code or image. A common example is a central logging agent
6.taint and toleration question.
7.how does scheduler place pods in nodes so quickly.
Ans:The scheduler finds feasible Nodes for a Pod and then runs a set of functions to score the feasible Nodes, picking a Node with the highest score among the feasible ones to run the Pod. The scheduler then notifies the API server about this decision in a process called Binding.
==========================================================
helm
1.

==========================================================
AWS-interview Questions.

Questions realted to ec2 that might be possible to be asked in interview.
1.What are the type of virtulization do we have on AWS Platform?
Ans:There are two types of Virtualization hvm and paravirtual and both have their own advantage and disadvantage. in reated to disk I/O or network realted operations.

2.What are the types of root devices?
Ans EBS, Instance store and what is the defference in these two: instance storage is an attage storage and this is not persistent if any thing happens to the device and EBS is a remote storage SAN or NAS and this is persistent storage

3.What are the type of hypervisor in AWS?
ans:xen and nitro and nitro is faster hypervisor. and why.

4.how can we recover the lost ec2 key?
ans:

5. how to check share AMIs?
ans:we have public private and owned by someone.

6.What is T2/T3 unlimited options?
ans:T2 and T3 are the credit that has been prealocated to user to use.

======================================
Amazon VPC:
1.list The componenets of use to build vpc?
Ans: Subnet,internetgateway,route table,cidr.
2.how many vpc can we create in a vpc?
Ans: it's depend on many factors like vpc size region etc defaul is 20 per vpc.
3.can we connect two vpc in different regions?
Ans: Yes, you can connect two VPCs in different regions. This is known as an inter-region VPC peering connection
4.What is vpc peering and how you will implement it and can you please give a demo?
Ans: 

==============================================================
EKS
how do you automate kuberntes deployement?
ans:developer---> github---jenkinswill build docker image---> to ECR----> jenkins.helm/kubectl---> kubernetes cluster.
2.How do you secure kuberntes app?
Ans:there are two aspects of kubernets Security.
			application security and DevOpSec cycle security.
			authorization,scan repo
			application security: RBAC, ABAC.
3. How do you cost/performance optimize kubernetes app?
Ans:Related to the controlplane (not much to improve as it is fixed)
	workder node number and types
	Unused CPU/memory allocation
	we can use cloud wath container insights/kubecost/cloudhealth/krr.
4.what are the challenges that you have faced in k8s?
Ans:Kubernetes version upgrade for worker nodes on EKS
	create/rehydrate AMI
	keeping application up and running
	keeping application highly available
	maintianing Pod distuption budget
	one click update
5. How do you scale kubernetes?
	horizantal Pod autoscaler(HPA)
	Cluster Utoscaler--- increase nodes
	cluster Overprovisioning(Real World App)
	pause conatiner:
6. how to expose kuberntes cluster to outside world?
Ans: we can use noteport,loadbalancer,clusterIP

What is the difference between cmd and entrypoint in docker.
Entrypoint:this instruction cannot be overriden but command can be .
CMD: Sets default parameters that can be overridden from the Docker command line interface (CLI) while running a docker container. ENTRYPOINT: Sets default parameters that cannot be overridden while executing Docker containers with CLI parameters.
======================================================
IAM: iam is universal account and it does not have relies to a region
	new user won't have any access when created
	user are granted with access key and secret key id when created
	we can rotate our password based using custoum policy.
==========================================================
S3.
What is S3?
Ans:S3 is an object level storage in aWS, it's simple storage service.

2.What is the difference between object storage and block storage?
Ans:Object storage means we have to override the object whereas block storage continues from the previous state.
Block storage is fast, and it is often preferred for applications that regularly need to load data from the backend. Object storage is a method for saving large volumes of unstructured data, including sensor data, audio files, logs, video and photo content, webpages, and emails.

3.How much data can i store in Amazon S3?
Ans:Around 256TB storage.

4.What storage classes does Amazon S3 offers?
Ans: S3 Standard, S3 Intelligent-Tiering, S3 Standard-IA, and S3 One Zone-IA and storage class is applicalble to object level.

5.Howreliable is Amazon S3?
Ans: 99.9

6. What is a provisioned Capacity unit(PCU) and when should it use pcu?(150/MB/s)
Ans: we can have provision unit deal with Amazon s3 so that we can retrive our data at a faster rate

7.S3 is a global service!! Why do i need to select a region while creating S3 bucket?
Ans:latency,

8. how do decide where to store a data?
Ans:Depends on where are your customer.

9.What checksus doesAmazon S3 employ to detect data corruption?(MD5 checksums & cyclic redundancy checks)

10.what is versioning?
Ans: We can version our objects in aws to know what has been changed and this will charge for versioning.

============================================================
EBS:

1.EBS: EBS provides high-performance block storage that is opti-mized for andom access operations. EBS volumes can deliver up to 64000 IOPS and 1000mb/s of the throughput per volume.

2.persistent: EBS volumes are persistent, which means that the data stored on them is retained even after the instance is terminated. This makes it easy to store and access large amounts of data in the cloud.

3.snapshots: EBS allows you take pont-in-time snaphots for our volumes. snapshots are stored in Amazon Simple Sotrage Services(S3),which pro-vides durability and availability. 

4.Encryption: EBS volumes can be encrypted at rest using AWS Key Management Service (KMS). This provides an additional layer of security for your data.

5.Availability: EBS volumes are designed to be highly available and durable. EBS provides multiple copies of your data within an Availability Zone (AZ), which ensures that your data is always available.
===============================================================
EFS:
Elastic file storage:
What are the main use cases for using Amazon EFS?
Ans:Amazon EFS is a serverless, fully elastic file system that provides high levels of durability and availability for your workloads and applications, including big data and analytics, media processing workflows, content management, web serving, and home directories


================================================================
Terraform interview questions

What is a terraform module?
Ans: A module in a terraform is a set of configuration files within a single directory it can have one or more files.
There are three types of Modules in terraform:
1.root module: As the name implies, this module is the root of any configuration. Every Terraform configuration consists of the root module as the main directory that works with the .tf files
module "vpc" {
 source  = "spacelift.io/your-organization/vpc-module-name/aws"
 version = "1.0.0"
[...]
2. child module: this is a module in which is being called by a root module and this is a reusable module as well.
3.published module: Published Modules are modules pushed to a private or public repository. Terraform registry is the primary public repository. It hosts freely-accessible modules that can be used by anyone within their configurations. Terraform will automatically download the necessary modules from the registry when the appropriate source and version are defined in the module block.


==========================================================================
Terraform Import, Tainting Resources and Debugging:
Terraform Taint: The terraform taint command informs Terraform that a particular object has become degraded or damaged so it will try to create in the next apply face.

Debugging:we can enable debugging in terraform to know more related to error in terraform and we can use env variable.
example: export TF_LOG=TRACE.  and to store logs as persistent we need to use export TF_LOG_PATH=/tmp/terrafomr.log



What are the componenets that you have created using terraform?
Ans: some of the componenets which  i have created using terraform are like s3,ec2,vpc,etc.tmp/
unset TF_LOG_PATH: this is to unset the error logs.

Terraform Import:Import command is use to import existing infrastructure in a terraform configuration.
resource "aws_instance" "myvm" {
 ami           = "unknown"
 instance_type = "unknown"
}

terraform import aws_instance.myvm <Instance ID>


Data_sources: we can use data to read resources created by other tools or console.
terraform import: this command is use to import existing resource and syntax is terraform import resource_type.resource_name attribut.
by above command terraform confg file won't be updated instead the state file will be updated.

Terraform State:
Introduction to Terraform State:state file in terraform maps the real world infrastructe with the resource definition file.

Purpose of State: is to track real world with current config, and it is use to manage state of infor when deal with team memebers.

rsource dependency in terraform:

Update and Destroy Infrastructure:

Remote State:
	What is Remote State and State Locking?
	remote state is a state file where we can keep in remote backend as we use that file is being used by different team memebrs as well as provide security.

Remote Backends with S3:
Terraform State Commands: terraform state file are not mean to be edited by vi tool instead we can use terraform state command that is listed below.
list,mv,show,pull,rm.

terraform state show aws_instance.fiannce.








2.how can you change or modify the exisiting infrastructe.
Ans:we can use import command.

3.what is mean by terraform state file.
Ans: Terraform maintain a state filw which maps the current state of infr with the confirugation. and it is mostly in local machine or we can store in terraform cloud or in s3 bucket as it may contain sensetive confirugation as well.

4.what happens if you lost your terraform state file?
Ans:Terraform will compare the cloud infra with the expected state file so if we lost the state file too we still can import the actual infa from the cloud using thier provide.

5.What are the major features that terraform have and why it is more popular then other tools?
Ans: the major features of terraform are like it have many plugins where we can use single file with multiple providers. it uses HCL language and terraform have simple syntax and can can quickly spin the resources using terraform.

6.What is mean by terraform validate?
Ans: this command will check for the terraform syntax and if there is any error it will thorow.

7.what is mean by lifecycle in terraform?
ans:init, plan apply 

lifecycle is a nested block that can appear within a resource block. The lifecycle block and its contents are meta-arguments, available for all resource blocks regardless of type. The arguments available within a lifecycle block are create_before_destroy , prevent_destroy , ignore_changes , and replace_triggered_by

8.there are 20 resources in public cloud and can we destroy only 1 resource out of 20 resources.
Ans:yes we can use destroy_target_resource.

9.Have you evered preserved the key used in terraform.
Ans: this is a key that we genrally gerated from the aws for the cli access and we can use this key for the use to set in their home directory.

10.what are the different types of modules in terraform?
ans: root,child and publish module.

11.


variable 'bk'{
region = 'esast-2'
descrption='wrhoera'
}

How can we prevent corrupting terraform state file and what are the methods to recover from tate file.

What is terraform workspace?


=======================================================================================================

kubernetes interview questions.

Top kubernetes interview by top company.

What is mean by ingress in kubernetes.
=> By Ingress in kubernetes it is an API object wherein we can use to define routing policy. where an external user can access pod in a cluster.


Pod Networking:

CNI: implements pod as well as node networking.
Ipam: ip address management in kubernetes. but who assigns ips to pod and nodes.
service networking:kube-proxy implements service networking in a cluster and it run in every node and gets ips address ragne from kubeaip component.
cluster DNS:kubernetes create subdoiman for svc and keep an entry of the service but it does not keep record of pod but we can make it that as well.
coredns:
Ingress: In Kubernetes, an Ingress is an object that allows access to Kubernetes services from outside the Kubernetes cluster.
===========================================================================================================
What is the difference between Docker and Kubernetes?
Ans: Docker is a container runtime engine whereas kuberntes is an orcherstaiont open-source platform where it usesruntime engine to manage it's enviornment.

2.What are the main components of kuberetes?
Ans: on a broarder level it have two components controle plane and a data plane or a worker node.
etc,apiser,c-cm,cm,sch, kubelet,kube-proxy,cr.

3.what is the difference between docker swarm and kubernetes?
Ans:A pod in a k8s is a runtime specification of a container and it is one if the smallest execution unit in kuberntes and pod are ephemeral by nature.
ubernetes is designed to work with any programming language and framework, while Docker Swarm only works with the Docker Engine API.
4.What is a namespace in kubernets?
Ans: namespace in kubs is logically isolating the resources in their own space and it gives one form of security as well.

6. what is the role of kube-proxy?
the role it is to create networking servcie in a kuberetnts cluster.

========================================
Linux

how will you change default user id value in linux?
ans: useradd biken -- to add user in linu, and to change the id range we have to edit the file /etc/login.defs

2.root# rm -rf /tmp/test gives error operation not permitted. Reason?
ans: touch /tmp/test
chatter +i /tmp/test---this character attrbute ensure that file or folder would not be deleted even by the root user.

3./etc/hosts/ which RPM is responsible for creating this file.
ans:we check using rpm -qf /etc/hosts  files which are owned by packages can be cheked using above command.

4.what is the difference betwwen RPM and YUM?
ans:both are use to manage software in centos/redhat. 
to check the depindency we can use rpm -qPR hpptd.6.6.7.rpm
rmp -ivh httpd.1.23.rpm

5. what is the difference between hardlink and softlink.
Ans:ln /tmp/test /etc/biken
ll -i /etc/biken ---- the inode value remains the same in the case of harlink.
ln -s /tmp/test /mnt/biken
ll -i /mnt/biken
rm /tmp/test  in this case link will be broken.

6.what is a sticky bit in linux?
Ans:sticky bit is implemtmed to prevent deletion of any folder and this is only applicable to folder level not in file level.
chmod +t dir  or chmod 1777 dir

7.how you will check open ports in linux server?
ans:netstat -tunlp 

8.how you will check open ports in remote server without login.
Ans: we can use command line utility to check the remote open port. nmap -A server-name/hostip.

9.your site is throwing 500 error how you will start troubleshooting?
ans:datbase is not responding.

10.how you will start troubleshooting if the site is down?
Ans:depending on the erro code we have to start.

11.how will you create a disk space if it is 100% occupied?
ans:we can use df -HT and go inside the directory and use du -sh *.

12.what is sar command in linux and do you and what is the package of sar?
ans;sar command can be used to see the info of the systme and it's stastical data.
we have to install utility/package to see it  yum sysstat. and after that restrt and check.
sar -q.

The sar command is a standard UNIX command used to gather statistical data about the system. With its numerous options, the sar command provides queuing, paging, TTY, and many other statistics. The sar -d option generates real-time disk I/O statistics.

=============================================================================================
git interview questions:
git diff-- linux command to check compare the files content.
.git is a floder which got downloaded when we initilize a git repo. and this ensure to track and contains git functinalty.
git log-- is to see who made or commit the code.
git push master origin.
git remove -v -- this command tells where is the remote refernece.
git remote add "githuburl" "reponame"
git clone url---for pulling the code from the repo.
git clone vs fork: Cloning makes a local copy of a repository, not your own copy. whereas fork will create a copy for you in a remote location.
Your own copy means that you will be able to contribute changes to your copy of the repository without affecting the original repository
git branch  biken
git checkout -b biken
git merge, git rebase or git cherry-pick.
git log division-- to check the commit in division branch
git cherry-pick: cherry-pick can be use when there is one or 2 commit but this is not helpful when we have thousands of commit.
git merge branchname / git merge mergeExample  when multiple people making a change in the same file in different it will throigh conflict as it will ask which code to commit.
git rebase branchname==> this will list the commit id at the top.
know more on git commands 



================================================================
sag interview role  questions:
txt files in dir.

#!/bin/bash

cd biken
aws s3 cp .  s3://bucketname\ --recursive
=============================
useradd admin

git clone giturl.

git checkout giturl

add a text file.

git add textfile
git commit -m "add textfile"

git checkout giturl

git cherry-pickt id

=================================
how do you see logs for deployment ###
kubectl logs deployment biken 

can we add multiple load balancer

==========================================
shell scripting part1: done with basic
shell scripting part2:
df -ht
free-- to check memory info
nproc

let's write a shell script to get the node/cpu info of a machine.

#!/bin/bash

###############################
#Author: Biken
#Date: 08/14/2023
# This script output the health of a node.
set -x #debug mode
df -h
free -g
nproc

to get the list of running process-> ps -ef, ps -ef | grep "amazon", this is to get the list of process

date | echo "This is today date"
this does not give the time because this date command belongs to stdin not to stdout or stderr

awk command: know little bit about it and the usecase.
ps -ef | grep amazon | awk -F "" '${print $2}'

set -e: exit the script when there is an error.
set-o pipefail: when pipe command fail then we can error out as well.

curl command: is use to retrieve the info fromthe internet example of getting the log file.
curl https:\\biken.com | grep error.

wget actually downloads the files. whereas curl command will look for and error
find /etc -name biken.txt // this is the format of using find command

let's write a simple if ifelse for loop in linux.

a=10
b=20

if [ $a gt $b ]
then
	echo "bbbbbbb"
else
	echo "bbbbbbbb"
fi

for loop
for i in {1...200}; do echo $1; done

trap command:know more on this
===============================================
shell scripting interview questions.
write a simple shell script to list all the processes
#!/bin/bash

ps -ef | awk -F " " '{print $2}'

write a shell script to print only error log from remote

curl google.com | grep error

for i in {1...100}; do
if ([`expr $i % 3` == 0 ] || [`expr $i % 5` == 0 ]) && [`expr $i % 15` !=0 ];
then
	echo $i
fi;
done

write a shell script to print "S" in missisipi

x=biken

grep -o "b" <<<"$x" | wc -l

what is crontab in linux and give one example?

how do you open a file in read only mode?
vi -r biken.txt

what is the dfference between soft and hard link?

what is the difference between break and continue in a loop?

what is the method you use to sort files in linux?
sort command

how you will manage huge logs in linux when you have multiple apps?
logrotate

Write a script to report the usage of AWS project?
configure aws account with awscli using aws configure
if you want to check aws cli command realted go to aws reference page.

#!/bin/bash

##############################
#Author: Biken
#Date:08-15th-2023  8730830223
#Version: V1
#This script will send the report to a user
#################################
#AWS S3
#Aws ec2
#aws lambda
#aws Iam

###############################
integrate with a cron tab the same above script.
================================================
Github API integration using shell script.
go through it and try to do it.

================================================
Ultimate shell script project used by Netflix Live Demo AWS Real-time project.
================================================
Permision:
who assign default permission to files and directories in linux?
What is Umask in Linux? Umask (short for user file-creation mode mask) is used by UNIX-based systems to set default permissions for newly created files and directories









=================================================
Route 53:
What is route 53?
=====================================================

VPC with public-private subnet.
AWS project of implementing a vpc project.
What is route 53 and how to implement it and use in real project.?
2 AZ---AZ
VPC
S3 gateway 
public subnet         public sebnet
NAT gateway   application load balancer    NAT Gateway
  private subnet               private subnet
                    Auto scaling group
	Server                        Server
                    Security group
implement this using console as well as terraform.
steps to implement:
1.create a VPC with vpc and more option.
2.create autoscaling group/// autoscaling group can't be created directly so create a launch template.
3.create bastion host as a single ec2 instance and edit the vpc as it should be in same vpc.
4.connect to the bastion host  and install simple html page python3 -m http.server 8000
5.create load balancer with ec2 server as target group, first create atarget group.
6.biken

==========================================================
Day-8:
AWS interview questions:
1. you have been assigned to design a VPC architecture for a 2 tier application. The application needs to be highly available and scalable. How would you design the VPC architecture?

Ans:

2. your organization has a VPC with multiple subnets. You want to restrict outbound internet access for resources in one subnet, but allow outbound internet access for resources in another subnet. How would you achieve this?

ans:



===============================================================
Day-9:
Aws s3 buckets deep dive:
S3 is called as globally accessible service.
Benefits or advantages of s3.
Availability & durability
Scalability
security
cost
performance

do practical part later.

====================================================================
AWS CLI Deep Dive:
we can only create two access key per account.
======================================================================
IAC with CFT aws:
create ec2 instance using CFT.
write cloud formation template
write a yaml file to create ec2 instance in aws
how does auto scaling manages spinning up instances when there is high traffic and removes instance when there is no traffic.
========================================================================
AWS CICD:
AWS provides a comprehensive set of CI/CD(continous Integration/Continuous Deployment) services that enable developers to automate and streamline their software delivery processes.
==========================================================================
AWS codepipeline:
AWS ci process with simple flask application.
===========================================================================
Day-17.
Day-29: How to crack the AWS Devops jobs.
Day-19. AWS lambda
search for lambda in aws console and perform a demo of sinning up.
Day-20: cost optmization demo with lambda function use by devops engineer
implementing lambda function to detect unused EBS volume in aws account and notifying to the creator.
step1: create ec2 instance
step2: take a snapshot of the ebs
step3:create lambda function
note: the default execition time for a lambda is 3s
step4: do it completely the demo
================================================================================

























shell scripting basic devops questions
==================================================================================

Understanding the jenkins pipeline:
go to this github repor and do the stuff: https://github.com/devopsjourney1/jenkins-101/blob/master/Jenkinsfile
Zero to Hero:


========================================================================================
kubernetes real time troubleshooting issue and examples.
kuberneres cluster problems
kubernetes Debugging & troubleshooting
1. ImagePullBackoff error=> invalid image/wrong tag
2.pod in pending state
3crashLoopBackOf=>
4.pod is in pending state.
5.OOM killed=> What is OOM? Types of OOM? How to fix? Challenges? tools?
		node OOM and container limit quoto set by kubernetes admin.
6.security is a top most challange in kubernetes
7.load balancing: There are many ingress controller but production grade load balancer like F5(Big-IP) are not easy to integrate with kubernetes.
8.obserbility: logs,metric and trace.
9.What are the some of the challanges with prometheus?
ans:

10. How do you handle kubernetes security?
Ans: there are many wasy that we can do some of them are:
	By default all pod can communicate with any other pod we can stop by using network policy and limit the communication.
RBAC(Role base access control)
Use namespaces for multi tenancy
Set the admission control policies to avoid running the privilages containers.
Turn on audit loggin.

11. How two containers running in a single pod have single IP address?
ans: kubernetes makes use or pause containers for shaing networning.
12. What is service mesh and why do we need it?
Ans: A service mesh ensures that communication among containerized and often ephemeral application infra service is fast reliable and sercure. The mesh provides critical capabiltes includng service discovery loadn balancing, encrypting.

13. What is a Pod disruption Beudget?

ans: A PDB specifies the number of replicas that an application can tolerate having realtive to how many it is intended to have.
14. What is a custom controller? Did you build one and how to build one?

Ans: kubernetes ingress controller or service mesh is an custom controller.

15. What is a side car container and when to use it?
Ans:

16. What is a Pod security policy?
Ans:

17. what is livenessprobe?
ans: Liveness probes are used to determine if a container is alive or dead. If a container fails a liveness probe, Kubernetes will kill the container and restart it as per the container's restart policy. Liveness probes are useful for detecting when an application has stopped responding and needs to be restarted.

18. what is a redninessprobe?
ans: Readiness probes are used to determine if a container is ready to accept traffic. If a container fails a readiness probe, Kubernetes will remove the container from the service endpoints, meaning that no traffic will be routed to that container until it passes the readiness probe. Readiness probes are useful for ensuring that a container is fully initialized before it begins accepting traffic.

19. What is a startuprobe?
ans:Startup probes are used to determine if a container has started up successfully. Startup probes are similar to readiness probes, but they are used specifically during the startup phase of a container. If a container fails a startup probe, Kubernetes will kill the container and restart it. Startup probes are useful for detecting when an application needs more time to start up than expected.




=======================================================================
Create kubernets cluster in eks:
create vpc
create extra subnet for kubernetes
create ec2 instance
create security group for kubernetes
create IAM role
creat IAM policies
attach Roles
create EKS cluster
create node group

=================================================================================
write a simple jenkins pepeline method.
pepeline {
	agent {
	docker {image 'node:16-alpine'}
}

stages {
	stage('Test'){
	steps{
	sh 'node --version'
}
}
}
}

======================================================================================

simple nodejs  docker file.
FROM node:18
WORKDIR /src/usr/app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 8080
CMD ['node', 'server.js']

======================================================================================
* * * * * sh /path/to/script.sh
minutes, hours, Dayof month, Month, Weekday.

=========================================================================================

linux reboot process step by step:

1. Step1: Power On and POST: When you power on your machine, it performs a Power-On Self-Test (POST) to ensure all hardware necessary for the system to operate is functioning correctly.
2.BIOS/UEFI: The BIOS/UEFI (Basic Input/Output System or Unified Extensible Firmware Interface) is then loaded. This low-level software checks the hardware and then scans the system's storage devices for bootable media.
3.MBR and GRUB: Once a bootable device (like your hard drive) is found, it reads the first 512 bytes known as the Master Boot Record (MBR) or, in newer systems, it uses the GUID Partition Table (GPT). The MBR/GPT contains the bootloader (often GRUB in Linux systems), which is then executed.
4.Kernel Loading: The GRUB menu allows you to select an operating system (in a dual boot scenario) or different kernel versions. GRUB/GRUB2 then loads the selected Linux kernel into memory.
5.Initramfs: The bootloader also loads a special filesystem called the initramfs (Initial RAM FileSystem) into memory alongside the kernel. This temporary root filesystem includes the drivers and tools needed to mount the actual root filesystem.
6.Kernel Initialization: Once loaded, the kernel decompresses and initializes itself, sets up system functions (like hardware interfaces, memory management, process control, etc.), and then extracts the initramfs archive in memory.
7.Switch Root: The kernel then executes the /init program located in the initramfs, which continues the boot process, typically by locating and mounting the actual root filesystem. The kernel then 'switches' from the initramfs to the newly mounted root filesystem.
8.Init and Runlevel/Targets: After the root filesystem is mounted, the kernel starts the first process init (or systemd in most modern systems). This process continues the boot process by moving the system into a specific runlevel, which dictates what processes or services to start.
9.User-Space: Init or systemd starts the necessary user-space processes according to the chosen runlevel.
10.Login: Finally, a login prompt or graphical user interface (GUI) appears, and the system is ready for user interaction.


====================================
jenkins zero to hero: keys points.
Jenkins interview questions:
What is master slave in jenkins?
Ans: 
===================================
AWS: Elastic load balancer.
There are three types of AWS load balancer.ALB,NLB,GLWB
ALB: application load blancer is mostly a lyer 7 and accepts taffic at layer 7 and it is slow as it need to do some sort of routing based on path or route.

NLB: network load balancer is at lyer4 and it does some sort of data packets and divide the data into chunk and it is faster and it uses sticky session/bit.

GWLB: this is mainly used in firewall,vpn and some other virtual appliances(vpn or any other type of appliances)
======================================
write a simple shell script to monitor docker containers.
#!/bin/bash


containers=$(docker ps -a)
 
for continaer in $containers; do
name=$(echo $container | aws '{print $1}')


================================================
#!/bin/bash

# Get the list of all running containers
CONTAINERS=$(docker ps -a)

# Loop through the list of containers
for CONTAINER in $CONTAINERS; do

  # Get the name of the container
  NAME=$(echo $CONTAINER | awk '{print $1}')

  # Get the status of the container
  STATUS=$(docker inspect --format='{{.State.Running}}' $CONTAINER)

  # Check if the container is running
  if [ "$STATUS" = "true" ]; then
    echo "$NAME is running"
  else
    echo "$NAME is not running"
  fi

done



































                      


















































======================================================
Kubernetes

1.what is kubernetes KOps?
Ans: Kops is an automation tool through which we can automate and bootstrap kubernetes cluseter
2.Explain Replicatio controller in K8s.
Ans: it is one of the component if kubernetes.
3.What is pv and pvc in kuberntes.
Ans: done   
4.a pod can't access a volume what could be the issue.
Ans: there can be access mode issue or pv type being accessed and ebs can be accessed by one pod and NFS can be by many pods
5.what is a side car container?
Ans:Sidecars are not part of the main traffic or API of the primary application. They usually operate asynchronously and are not involved in the public API. This way, they can enhance the main container without modifying its code or image. A common example is a central logging agent
6.taint and toleration question.
7.how does scheduler place pods in nodes so quickly.
Ans:The scheduler finds feasible Nodes for a Pod and then runs a set of functions to score the feasible Nodes, picking a Node with the highest score among the feasible ones to run the Pod. The scheduler then notifies the API server about this decision in a process called Binding.
8. What is the difference between deployment and stateful sts in kubernetes.
Ans:have a check by creating it.


==========================================================
helm
1.

==========================================================
AWS Interview  questions:
What is durability,Reliability,availability?
Ans: Durability is how safe the data is from being lost, availability is how much efficient the service is to operate and reliabliity is how consistent the service is to use.

Can we have multiple inernet gateway for single vpc?
Ans: No, why it is no.

What is an internet gateway?
Ans: IgW allows both inbound and outbound access to the internet whereas the NAT Gateway only allows outbound access. Thus, IgW allows instances with public IPs to access the internet whereas NAT Gateway allows instances with private IPs to access internet.

what is vpc peering?
Ans: enabling the connection between two vpc in either way and vpc peering cannot be done in different regions

what is a NAT instance?
Ans: A NAT instance provides network address translation (NAT). You can use a NAT instance to allow resources in a private subnet to communicate with destinations outside the virtual private cloud (VPC), such as the internet or an on-premises network.
and nat instance is owned managed resource and it can have both public and private ips.

What is NAT Gateway?
Ans: NAT gateway is use to translate private ips to different address to communicate to outside world or pubic internet. it uese pvc firewall for security purpose.

What are three services available on Route 53?
Ans: DNS registration, health check and routing.

Does Route 53 Do load balancing?
Ans: yes route53 does global server load blancing base on the user geo location region.

What is A,Cname,AAA records and how they are different?
Ans: An A record points a domain name to an IPv4 address, which is an older type of IP address.
	An AAAA record points a domain name to an IPv6 address, which is a newer type of IP address that allows for more unique addresses
	A CNAME record points a hostname to another hostname or FQDN (Fully Qualified Domain Name), which is the complete domain name for a specific computer or host.
	if any confusion check here: https://www.linkedin.com/pulse/dns-records-demystified-understanding-aaaa-cname-mohamed-abdul-hameed/

How can we add a load balancer to Route 53?
Ans: we can follow usual steps to route trffic in a load balancer.

Does Amazon Route 53 support NS records?
Ans: Yes, Amazon Route 53 supports Name Service (NS) records.

How we can add Cname to Route 53?
Ans: A CNAME record cannot be created for the Parent,or Apex domains. An alias record can be used with Route 53 to point the parent domain to other supported alias targets.

What are the componenets of VPC?

Ans: The componenets of VPC are: internetgateway, route table, subnets, cidr, Natgateway, loadbalancer, Nat instance, NACL is at subnet loadbalancer, sroute if through loadbalancer, and security group, vpc flow logs to chekc the user reauets.

What is security group, NACL  and where it is applicable?
ANs: By default AWS will not accept any traffic. 
	Security group is at instance level.
	AWS doesnot allow port 25 as this is use for mailing activity.

	just run simple python app:  python3 -m http.server 9000

===============================================================
Route53:
do some projects refering aws route53 documentation.

======================================================================






	











=========================================================================
Load balancer interview qiestions:






Questions realted to ec2 that might be possible to be asked in interview.
1.What are the type of virtulization do we have on AWS Platform?
Ans:There are two types of Virtualization hvm and paravirtual and both have their own advantage and disadvantage. in reated to disk I/O or network realted operations.

2.What are the types of root devices?
Ans EBS, Instance store and what is the defference in these two: instance storage is an attage storage and this is not persistent if any thing happens to the device and EBS is a remote storage SAN or NAS and this is persistent storage

3.What are the type of hypervisor in AWS?
ans:xen and nitro and nitro is faster hypervisor. and why.

4.how can we recover the lost ec2 key?
ans:

5. how to check share AMIs?
ans:we have public private and owned by someone.

6.What is T2/T3 unlimited options?
ans:T2 and T3 are the credit that has been prealocated to user to use.

==============================================================
EKS
how do you automate kuberntes deployement?
ans:developer---> github---jenkinswill build docker image---> to ECR----> jenkins.helm/kubectl---> kubernetes cluster.
2.How do you secure kuberntes app?
Ans:there are two aspects of kubernets Security.
			application security and DevOpSec cycle security.
			authorization,scan repo
			application security: RBAC, ABAC.
3. How do you cost/performance optimize kubernetes app?
Ans:Related to the controlplane (not much to improve as it is fixed)
	workder node number and types
	Unused CPU/memory allocation
	we can use cloud wath container insights/kubecost/cloudhealth/krr.
4.what are the challenges that you have faced in k8s?
Ans:Kubernetes version upgrade for worker nodes on EKS
	create/rehydrate AMI
	keeping application up and running
	keeping application highly available
	maintianing Pod distuption budget
	one click update
5. How do you scale kubernetes?
	horizantal Pod autoscaler(HPA)
	Cluster Utoscaler--- increase nodes
	cluster Overprovisioning(Real World App)
	pause conatiner:
6. how to expose kuberntes cluster to outside world?
Ans: we can use noteport,loadbalancer,clusterIP

What is the difference between cmd and entrypoint in docker.
Entrypoint:this instruction cannot be overriden but command can be .
CMD: Sets default parameters that can be overridden from the Docker command line interface (CLI) while running a docker container. ENTRYPOINT: Sets default parameters that cannot be overridden while executing Docker containers with CLI parameters.
======================================================
IAM: iam is universal account and it does not have relies to a region
	new user won't have any access when created
	user are granted with access key and secret key id when created
	we can rotate our password based using custoum policy.
==========================================================
S3.
What is S3?
Ans:S3 is an object level storage in aWS, it's simple storage service.

2.What is the difference between object storage and block storage?
Ans:Object storage means we have to override the object whereas block storage continues from the previous state.
Block storage is fast, and it is often preferred for applications that regularly need to load data from the backend. Object storage is a method for saving large volumes of unstructured data, including sensor data, audio files, logs, video and photo content, webpages, and emails.

3.How much data can i store in Amazon S3?
Ans:Around 256TB storage.

4.What storage classes does Amazon S3 offers?
Ans: S3 Standard, S3 Intelligent-Tiering, S3 Standard-IA, and S3 One Zone-IA and storage class is applicalble to object level.

5.Howreliable is Amazon S3?
Ans: 99.9

6. What is a provisioned Capacity unit(PCU) and when should it use pcu?(150/MB/s)
Ans: we can have provision unit deal with Amazon s3 so that we can retrive our data at a faster rate

7.S3 is a global service!! Why do i need to select a region while creating S3 bucket?
Ans:latency,

8. how do decide where to store a data?
Ans:Depends on where are your customer.

9.What checksus doesAmazon S3 employ to detect data corruption?(MD5 checksums & cyclic redundancy checks)

10.what is versioning?
Ans: We can version our objects in aws to know what has been changed and this will charge for versioning.

============================================================
EBS:

1.EBS: EBS provides high-performance block storage that is opti-mized for andom access operations. EBS volumes can deliver up to 64000 IOPS and 1000mb/s of the throughput per volume.

2.persistent: EBS volumes are persistent, which means that the data stored on them is retained even after the instance is terminated. This makes it easy to store and access large amounts of data in the cloud.

3.snapshots: EBS allows you take pont-in-time snaphots for our volumes. snapshots are stored in Amazon Simple Sotrage Services(S3),which pro-vides durability and availability. 

4.Encryption: EBS volumes can be encrypted at rest using AWS Key Management Service (KMS). This provides an additional layer of security for your data.

5.Availability: EBS volumes are designed to be highly available and durable. EBS provides multiple copies of your data within an Availability Zone (AZ), which ensures that your data is always available.
===============================================================
EFS:
Elastic file storage:
What are the main use cases for using Amazon EFS?
Ans:Amazon EFS is a serverless, fully elastic file system that provides high levels of durability and availability for your workloads and applications, including big data and analytics, media processing workflows, content management, web serving, and home directories


================================================================
Terraform interview questions

What is a terraform module?
Ans: A module in a terraform is a set of configuration files within a single directory it can have one or more files.
There are three types of Modules in terraform:
1.root module: As the name implies, this module is the root of any configuration. Every Terraform configuration consists of the root module as the main directory that works with the .tf files
module "vpc" {
 source  = "spacelift.io/your-organization/vpc-module-name/aws"
 version = "1.0.0"
[...]
2. child module: this is a module in which is being called by a root module and this is a reusable module as well.
3.published module: Published Modules are modules pushed to a private or public repository. Terraform registry is the primary public repository. It hosts freely-accessible modules that can be used by anyone within their configurations. Terraform will automatically download the necessary modules from the registry when the appropriate source and version are defined in the module block.


==========================================================================
Terraform Import, Tainting Resources and Debugging:
Terraform Taint: The terraform taint command informs Terraform that a particular object has become degraded or damaged so it will try to create in the next apply face.

Debugging:we can enable debugging in terraform to know more related to error in terraform and we can use env variable.
example: export TF_LOG=TRACE.  and to store logs as persistent we need to use export TF_LOG_PATH=/tmp/terrafomr.log



What are the componenets that you have created using terraform?
Ans: some of the componenets which  i have created using terraform are like s3,ec2,vpc,etc.tmp/
unset TF_LOG_PATH: this is to unset the error logs.

Terraform Import:Import command is use to import existing infrastructure in a terraform configuration.
resource "aws_instance" "myvm" {
 ami           = "unknown"
 instance_type = "unknown"
}

terraform import aws_instance.myvm <Instance ID>


Data_sources: we can use data to read resources created by other tools or console.
terraform import: this command is use to import existing resource and syntax is terraform import resource_type.resource_name attribut.
by above command terraform confg file won't be updated instead the state file will be updated.

Terraform State:
Introduction to Terraform State:state file in terraform maps the real world infrastructe with the resource definition file.

Purpose of State: is to track real world with current config, and it is use to manage state of infor when deal with team memebers.

rsource dependency in terraform:

Update and Destroy Infrastructure:

Remote State:
	What is Remote State and State Locking?
	remote state is a state file where we can keep in remote backend as we use that file is being used by different team memebrs as well as provide security.

Remote Backends with S3:
Terraform State Commands: terraform state file are not mean to be edited by vi tool instead we can use terraform state command that is listed below.
list,mv,show,pull,rm.

terraform state show aws_instance.fiannce.








2.how can you change or modify the exisiting infrastructe.
Ans:we can use import command.

3.what is mean by terraform state file.
Ans: Terraform maintain a state filw which maps the current state of infr with the confirugation. and it is mostly in local machine or we can store in terraform cloud or in s3 bucket as it may contain sensetive confirugation as well.

4.what happens if you lost your terraform state file?
Ans:Terraform will compare the cloud infra with the expected state file so if we lost the state file too we still can import the actual infa from the cloud using thier provide.

5.What are the major features that terraform have and why it is more popular then other tools?
Ans: the major features of terraform are like it have many plugins where we can use single file with multiple providers. it uses HCL language and terraform have simple syntax and can can quickly spin the resources using terraform.

6.What is mean by terraform validate?
Ans: this command will check for the terraform syntax and if there is any error it will thorow.

7.what is mean by lifecycle in terraform?
ans:init, plan apply 

lifecycle is a nested block that can appear within a resource block. The lifecycle block and its contents are meta-arguments, available for all resource blocks regardless of type. The arguments available within a lifecycle block are create_before_destroy , prevent_destroy , ignore_changes , and replace_triggered_by

8.there are 20 resources in public cloud and can we destroy only 1 resource out of 20 resources.
Ans:yes we can use destroy_target_resource.

9.Have you evered preserved the key used in terraform.
Ans: this is a key that we genrally gerated from the aws for the cli access and we can use this key for the use to set in their home directory.

10.what are the different types of modules in terraform?
ans: root,child and publish module.

11.


variable 'bk'{
region = 'esast-2'
descrption='wrhoera'
}

How can we prevent corrupting terraform state file and what are the methods to recover from tate file.

What is terraform workspace?


=======================================================================================================

kubernetes interview questions.

Top kubernetes interview by top company.

What is mean by ingress in kubernetes.
=> By Ingress in kubernetes it is an API object wherein we can use to define routing policy. where an external user can access pod in a cluster.


Pod Networking:

CNI: implements pod as well as node networking.
Ipam: ip address management in kubernetes. but who assigns ips to pod and nodes.
service networking:kube-proxy implements service networking in a cluster and it run in every node and gets ips address ragne from kubeaip component.
cluster DNS:kubernetes create subdoiman for svc and keep an entry of the service but it does not keep record of pod but we can make it that as well.
coredns:
Ingress: In Kubernetes, an Ingress is an object that allows access to Kubernetes services from outside the Kubernetes cluster.
===========================================================================================================
What is the difference between Docker and Kubernetes?
Ans: Docker is a container runtime engine whereas kuberntes is an orcherstaiont open-source platform where it usesruntime engine to manage it's enviornment.

2.What are the main components of kuberetes?
Ans: on a broarder level it have two components controle plane and a data plane or a worker node.
etc,apiser,c-cm,cm,sch, kubelet,kube-proxy,cr.

3.what is the difference between docker swarm and kubernetes?
Ans:A pod in a k8s is a runtime specification of a container and it is one if the smallest execution unit in kuberntes and pod are ephemeral by nature.
ubernetes is designed to work with any programming language and framework, while Docker Swarm only works with the Docker Engine API.
4.What is a namespace in kubernets?
Ans: namespace in kubs is logically isolating the resources in their own space and it gives one form of security as well.

6. what is the role of kube-proxy?
the role it is to create networking servcie in a kuberetnts cluster.



========================================
Linux

how will you change default user id value in linux?
ans: useradd biken -- to add user in linu, and to change the id range we have to edit the file /etc/login.defs

2.root# rm -rf /tmp/test gives error operation not permitted. Reason?
ans: touch /tmp/test
chatter +i /tmp/test---this character attrbute ensure that file or folder would not be deleted even by the root user.

3./etc/hosts/ which RPM is responsible for creating this file.
ans:we check using rpm -qf /etc/hosts  files which are owned by packages can be cheked using above command.

4.what is the difference betwwen RPM and YUM?
ans:both are use to manage software in centos/redhat. 
to check the depindency we can use rpm -qPR hpptd.6.6.7.rpm
rmp -ivh httpd.1.23.rpm

5. what is the difference between hardlink and softlink.
Ans:ln /tmp/test /etc/biken
ll -i /etc/biken ---- the inode value remains the same in the case of harlink.
ln -s /tmp/test /mnt/biken
ll -i /mnt/biken
rm /tmp/test  in this case link will be broken.

6.what is a sticky bit in linux?
Ans:sticky bit is implemtmed to prevent deletion of any folder and this is only applicable to folder level not in file level.
chmod +t dir  or chmod 1777 dir

7.how you will check open ports in linux server?
ans:netstat -tunlp 

8.how you will check open ports in remote server without login.
Ans: we can use command line utility to check the remote open port. nmap -A server-name/hostip.

9.your site is throwing 500 error how you will start troubleshooting?
ans:datbase is not responding.

10.how you will start troubleshooting if the site is down?
Ans:depending on the erro code we have to start.

11.how will you create a disk space if it is 100% occupied?
ans:we can use df -HT and go inside the directory and use du -sh *.

12.what is sar command in linux and do you and what is the package of sar?
ans;sar command can be used to see the info of the systme and it's stastical data.
we have to install utility/package to see it  yum sysstat. and after that restrt and check.
sar -q.

The sar command is a standard UNIX command used to gather statistical data about the system. With its numerous options, the sar command provides queuing, paging, TTY, and many other statistics. The sar -d option generates real-time disk I/O statistics.

13.

=============================================================================================
git interview questions:
git diff-- linux command to check compare the files content.
.git is a floder which got downloaded when we initilize a git repo. and this ensure to track and contains git functinalty.
git log-- is to see who made or commit the code.
git push master origin.
git remove -v -- this command tells where is the remote refernece.
git remote add "githuburl" "reponame"
git clone url---for pulling the code from the repo.
git clone vs fork: Cloning makes a local copy of a repository, not your own copy. whereas fork will create a copy for you in a remote location.
Your own copy means that you will be able to contribute changes to your copy of the repository without affecting the original repository
git branch  biken
git checkout -b biken
git merge, git rebase or git cherry-pick.
git log division-- to check the commit in division branch
git cherry-pick: cherry-pick can be use when there is one or 2 commit but this is not helpful when we have thousands of commit.
git merge branchname / git merge mergeExample  when multiple people making a change in the same file in different it will throigh conflict as it will ask which code to commit.
git rebase branchname==> this will list the commit id at the top.
know more on git commands 



================================================================
sag interview role  questions:
txt files in dir.

#!/bin/bash

cd biken
aws s3 cp .  s3://bucketname\ --recursive
=============================
useradd admin

git clone giturl.

git checkout giturl

add a text file.

git add textfile
git commit -m "add textfile"

git checkout giturl

git cherry-pickt id

=================================
how do you see logs for deployment ###
kubectl logs deployment biken 

can we add multiple load balancer

==========================================
shell scripting part1: done with basic
shell scripting part2:
df -ht
free-- to check memory info
nproc

let's write a shell script to get the node/cpu info of a machine.

#!/bin/bash

###############################
#Author: Biken
#Date: 08/14/2023
# This script output the health of a node.
set -x #debug mode
df -h
free -g
nproc

to get the list of running process-> ps -ef, ps -ef | grep "amazon", this is to get the list of process

date | echo "This is today date"
this does not give the time because this date command belongs to stdin not to stdout or stderr

awk command: know little bit about it and the usecase.
ps -ef | grep amazon | awk -F "" '${print $2}'

set -e: exit the script when there is an error.
set-o pipefail: when pipe command fail then we can error out as well.

curl command: is use to retrieve the info fromthe internet example of getting the log file.
curl https:\\biken.com | grep error.

wget actually downloads the files. whereas curl command will look for and error
find /etc -name biken.txt // this is the format of using find command

let's write a simple if ifelse for loop in linux.

a=10
b=20

if [ $a gt $b ]
then
	echo "bbbbbbb"
else
	echo "bbbbbbbb"
fi

for loop
for i in {1...200}; do echo $1; done

trap command:know more on this
===============================================
shell scripting interview questions.
write a simple shell script to list all the processes
#!/bin/bash

ps -ef | awk -F " " '{print $2}'

write a shell script to print only error log from remote

curl google.com | grep error

for i in {1...100}; do
if ([`expr $i % 3` == 0 ] || [`expr $i % 5` == 0 ]) && [`expr $i % 15` !=0 ];
then
	echo $i
fi;
done

write a shell script to print "S" in missisipi

x=biken

grep -o "b" <<<"$x" | wc -l

what is crontab in linux and give one example?

how do you open a file in read only mode?
vi -r biken.txt

what is the dfference between soft and hard link?

what is the difference between break and continue in a loop?

what is the method you use to sort files in linux?
sort command

how you will manage huge logs in linux when you have multiple apps?
logrotate

Write a script to report the usage of AWS project?
configure aws account with awscli using aws configure
if you want to check aws cli command realted go to aws reference page.

#!/bin/bash

##############################
#Author: Biken
#Date:08-15th-2023  8730830223
#Version: V1
#This script will send the report to a user
#################################
#AWS S3
#Aws ec2
#aws lambda
#aws Iam

###############################
integrate with a cron tab the same above script.
================================================
Github API integration using shell script.
go through it and try to do it.

================================================
Ultimate shell script project used by Netflix Live Demo AWS Real-time project.
================================================
Permision:
who assign default permission to files and directories in linux?
What is Umask in Linux? Umask (short for user file-creation mode mask) is used by UNIX-based systems to set default permissions for newly created files and directories









=================================================
Route 53:
What is route 53?
=====================================================

VPC with public-private subnet.
AWS project of implementing a vpc project.
What is route 53 and how to implement it and use in real project.?
2 AZ---AZ
VPC
S3 gateway 
public subnet         public sebnet
NAT gateway   application load balancer    NAT Gateway
  private subnet               private subnet
                    Auto scaling group
	Server                        Server
                    Security group
implement this using console as well as terraform.
steps to implement:
1.create a VPC with vpc and more option.
2.create autoscaling group/// autoscaling group can't be created directly so create a launch template.
3.create bastion host as a single ec2 instance and edit the vpc as it should be in same vpc.
4.connect to the bastion host  and install simple html page python3 -m http.server 8000
5.create load balancer with ec2 server as target group, first create atarget group.

==========================================================
Day-8:
AWS interview questions:
1. you have been assigned to design a VPC architecture for a 2 tier application. The application needs to be highly available and scalable. How would you design the VPC architecture?

Ans:

2. your organization has a VPC with multiple subnets. You want to restrict outbound internet access for resources in one subnet, but allow outbound internet access for resources in another subnet. How would you achieve this?

ans:



===============================================================
Day-9:
Aws s3 buckets deep dive:
S3 is called as globally accessible service.
Benefits or advantages of s3.
Availability & durability
Scalability
security
cost
performance

do practical part later.

====================================================================
AWS CLI Deep Dive:
we can only create two access key per account.
======================================================================
IAC with CFT aws:
create ec2 instance using CFT.
write cloud formation template
write a yaml file to create ec2 instance in aws
how does auto scaling manages spinning up instances when there is high traffic and removes instance when there is no traffic.
========================================================================
AWS CICD:
AWS provides a comprehensive set of CI/CD(continous Integration/Continuous Deployment) services that enable developers to automate and streamline their software delivery processes.
==========================================================================
AWS codepipeline:
AWS ci process with simple flask application.
===========================================================================
Day-17.
Day-29: How to crack the AWS Devops jobs.
Day-19. AWS lambda
search for lambda in aws console and perform a demo of sinning up.
Day-20: cost optmization demo with lambda function use by devops engineer
implementing lambda function to detect unused EBS volume in aws account and notifying to the creator.
step1: create ec2 instance
step2: take a snapshot of the ebs
step3:create lambda function
note: the default execition time for a lambda is 3s
step4: do it completely the demo
================================================================================

























shell scripting basic devops questions
==================================================================================

Understanding the jenkins pipeline:
go to this github repor and do the stuff: https://github.com/devopsjourney1/jenkins-101/blob/master/Jenkinsfile
Zero to Hero:


========================================================================================
kubernetes real time troubleshooting issue and examples.
kuberneres cluster problems
kubernetes Debugging & troubleshooting
1. ImagePullBackoff error=> invalid image/wrong tag
2.pod in pending state
3crashLoopBackOf=>
4.pod is in pending state.
5.OOM killed=> What is OOM? Types of OOM? How to fix? Challenges? tools?
		node OOM and container limit quoto set by kubernetes admin.
6.security is a top most challange in kubernetes
7.load balancing: There are many ingress controller but production grade load balancer like F5(Big-IP) are not easy to integrate with kubernetes.
8.obserbility: logs,metric and trace.
9.What are the some of the challanges with prometheus?
ans:

10. How do you handle kubernetes security?
Ans: there are many wasy that we can do some of them are:
	By default all pod can communicate with any other pod we can stop by using network policy and limit the communication.
RBAC(Role base access control)
Use namespaces for multi tenancy
Set the admission control policies to avoid running the privilages containers.
Turn on audit loggin.

11. How two containers running in a single pod have single IP address?
ans: kubernetes makes use or pause containers for shaing networning.
12. What is service mesh and why do we need it?
Ans: A service mesh ensures that communication among containerized and often ephemeral application infra service is fast reliable and sercure. The mesh provides critical capabiltes includng service discovery loadn balancing, encrypting.

13. What is a Pod disruption Beudget?

ans: A PDB specifies the number of replicas that an application can tolerate having realtive to how many it is intended to have.
14. What is a custom controller? Did you build one and how to build one?

Ans: kubernetes ingress controller or service mesh is an custom controller.

15. What is a side car container and when to use it?
Ans:

16. What is a Pod security policy?
Ans:

17. what is livenessprobe?
ans: Liveness probes are used to determine if a container is alive or dead. If a container fails a liveness probe, Kubernetes will kill the container and restart it as per the container's restart policy. Liveness probes are useful for detecting when an application has stopped responding and needs to be restarted.

18. what is a redninessprobe?
ans: Readiness probes are used to determine if a container is ready to accept traffic. If a container fails a readiness probe, Kubernetes will remove the container from the service endpoints, meaning that no traffic will be routed to that container until it passes the readiness probe. Readiness probes are useful for ensuring that a container is fully initialized before it begins accepting traffic.

19. What is a startuprobe?
ans:Startup probes are used to determine if a container has started up successfully. Startup probes are similar to readiness probes, but they are used specifically during the startup phase of a container. If a container fails a startup probe, Kubernetes will kill the container and restart it. Startup probes are useful for detecting when an application needs more time to start up than expected.




=======================================================================
Create kubernets cluster in eks:
create vpc
create extra subnet for kubernetes
create ec2 instance
create security group for kubernetes
create IAM role
creat IAM policies
attach Roles
create EKS cluster
create node group

=================================================================================
write a simple jenkins pepeline method.
pepeline {
	agent {
	docker {image 'node:16-alpine'}
}

stages {
	stage('Test'){
	steps{
	sh 'node --version'
}
}
}
}

======================================================================================

simple nodejs  docker file.
FROM node:18
WORKDIR /src/usr/app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 8080
CMD ['node', 'server.js']

======================================================================================
* * * * * sh /path/to/script.sh
minutes, hours, Dayof month, Month, Weekday.

=========================================================================================

linux reboot process step by step:

1. Step1: Power On and POST: When you power on your machine, it performs a Power-On Self-Test (POST) to ensure all hardware necessary for the system to operate is functioning correctly.
2.BIOS/UEFI: The BIOS/UEFI (Basic Input/Output System or Unified Extensible Firmware Interface) is then loaded. This low-level software checks the hardware and then scans the system's storage devices for bootable media.
3.MBR and GRUB: Once a bootable device (like your hard drive) is found, it reads the first 512 bytes known as the Master Boot Record (MBR) or, in newer systems, it uses the GUID Partition Table (GPT). The MBR/GPT contains the bootloader (often GRUB in Linux systems), which is then executed.
4.Kernel Loading: The GRUB menu allows you to select an operating system (in a dual boot scenario) or different kernel versions. GRUB/GRUB2 then loads the selected Linux kernel into memory.
5.Initramfs: The bootloader also loads a special filesystem called the initramfs (Initial RAM FileSystem) into memory alongside the kernel. This temporary root filesystem includes the drivers and tools needed to mount the actual root filesystem.
6.Kernel Initialization: Once loaded, the kernel decompresses and initializes itself, sets up system functions (like hardware interfaces, memory management, process control, etc.), and then extracts the initramfs archive in memory.
7.Switch Root: The kernel then executes the /init program located in the initramfs, which continues the boot process, typically by locating and mounting the actual root filesystem. The kernel then 'switches' from the initramfs to the newly mounted root filesystem.
8.Init and Runlevel/Targets: After the root filesystem is mounted, the kernel starts the first process init (or systemd in most modern systems). This process continues the boot process by moving the system into a specific runlevel, which dictates what processes or services to start.
9.User-Space: Init or systemd starts the necessary user-space processes according to the chosen runlevel.
10.Login: Finally, a login prompt or graphical user interface (GUI) appears, and the system is ready for user interaction.


====================================
jenkins zero to hero: keys points.
===================================
AWS: Elastic load balancer.
There are three types of AWS load balancer.ALB,NLB,GLWB
ALB: application load blancer is mostly a lyer 7 and accepts taffic at layer 7 and it is slow as it need to do some sort of routing based on path or route.

NLB: network load balancer is at lyer4 and it does some sort of data packets and divide the data into chunk and it is faster and it uses sticky session/bit.

GWLB: this is mainly used in firewall,vpn and some other virtual appliances(vpn or any other type of appliances)
======================================
write a simple shell script to monitor docker containers.
#!/bin/bash


containers=$(docker ps -a)
 
for continaer in $containers; do
name=$(echo $container | aws '{print $1}')


================================================
#!/bin/bash

# Get the list of all running containers
CONTAINERS=$(docker ps -a)

# Loop through the list of containers
for CONTAINER in $CONTAINERS; do

  # Get the name of the container
  NAME=$(echo $CONTAINER | awk '{print $1}')

  # Get the status of the container
  STATUS=$(docker inspect --format='{{.State.Running}}' $CONTAINER)

  # Check if the container is running
  if [ "$STATUS" = "true" ]; then
    echo "$NAME is running"
  else
    echo "$NAME is not running"
  fi

done
=================================================
I have 5 log files under different directores . say for eg abc under /home/dir1 , xyz under home/dir2 . is there a script that i can run from say /home that searchers all these files for string or combination of strings and write to a file

eg search file by timestamp|keyword
o/p in a file

for i in /dir1 /dir2 /dir3;
do
	grep "biken" "$i" /file_name >> file.output
done

========================================================
write script to display logs of GET response and response time and code from a log file?

Ans: 
Script to display logs of GET response and response time and code from a log file

Use grep command to filter GET requests from the log file

Use awk command to extract response time and response code from the filtered logs

Format the output using printf command

Example: grep 'GET' logfile | awk '{print $4, $9, $NF}' | printf '%-20s %-10s %-10s '
grep 'GET' filename | awk '{print $4, $9, $NF}' | printf '%-20s %-10s %-10s'

































                      






























